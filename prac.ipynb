{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import evaluate\n",
    "import model\n",
    "import training\n",
    "import influence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "from importlib import reload\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "dataset = dataloader.AmazonDataset(data_dir)\n",
    "evaluater = evaluate.Evaluater(data_dir)\n",
    "\n",
    "\n",
    "# 学習済みモデル読み込み\n",
    "mf = torch.load('model.torch')\n",
    "# loss_func定義\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "# 任意のテストデータ[u_i, i_i]ロード\n",
    "# あるユーザに対してランキング上位のアイテム\n",
    "target_user = dataset.user_list[0]\n",
    "target_user = dataset.user_list.index(target_user)\n",
    "ranking_idx = evaluater.predict(mf, target_user)\n",
    "target_item = ranking_idx[0]\n",
    "\n",
    "\n",
    "# trainingデータのinfluenceを計算\n",
    "## [u_i, i_i]のどちらかを含むtrainingデータを持ってくる\n",
    "train_data = []\n",
    "for row in dataset.user_item_train_df.values:\n",
    "    if target_user == row[0] or target_item == row[1]:\n",
    "        train_data.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(-2.1051e-07, grad_fn=<DivBackward0>)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "reload(influence)\n",
    "test_data = [target_user, target_item]\n",
    "influ = influence.get_influence(loss_func, train_data[0], test_data, mf)\n",
    "influ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "351000"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "len(dataset.user_list) * 65 + len(dataset.item_list) * 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss_func, train_data, model):\n",
    "    user = torch.tensor([train_data[0]], dtype=torch.long, device=device)\n",
    "    item = torch.tensor([train_data[1]], dtype=torch.long, device=device)\n",
    "    pred = model(user, item)\n",
    "    y = torch.tensor([1.])\n",
    "    loss = loss_func(pred, y)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_loss_gradient(model, loss):\n",
    "    grads = torch.autograd.grad(loss, model.parameters(), create_graph = True, retain_graph = True)\n",
    "    grad = []\n",
    "    for g in grads:\n",
    "        tmp = g.view(1, g.shape[0] * g.shape[1])\n",
    "        grad.append(tmp)\n",
    "\n",
    "    return torch.cat(grad, dim=1)[0]\n",
    "\n",
    "def hessian_vector_product_2(model, grad_loss, v):\n",
    "    w = torch.dot(grad_loss, v)\n",
    "    w.backward()\n",
    "    params = model.parameters()\n",
    "    hv = []\n",
    "    for p in params:\n",
    "        hv.append(p.grad.view(1, p.shape[0]*p.shape[1]))\n",
    "\n",
    "    return torch.cat(hv, dim=1)[0]\n",
    "\n",
    "def hessian_vector_product(model, grad_loss, v):\n",
    "    w = torch.dot(grad_loss, v)\n",
    "    grads = torch.autograd.grad(w, model.parameters(), retain_graph=True)\n",
    "    grad = []\n",
    "    for g in grads:\n",
    "        tmp = g.view(1, g.shape[0] * g.shape[1])\n",
    "        grad.append(tmp)\n",
    "\n",
    "    return torch.cat(grad, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_influence(loss_func, train_data, test_data, model):\n",
    "    loss = get_loss(loss_func, train_data, model)\n",
    "\n",
    "    grad_loss = get_loss_gradient(model, loss)\n",
    "    print(grad_loss)\n",
    "    v = torch.ones(grad_loss.size())\n",
    "    hv = hessian_vector_product(model, grad_loss, v)\n",
    "    print(hv.shape)\n",
    "    #hv2 = hessian_vector_product_2(model, grad_loss, v)\n",
    "\n",
    "    hv3 = hessian_vector_product(model, grad_loss, v)\n",
    "    #print(torch.norm(hv - hv2))\n",
    "    print(torch.norm(hv - hv3))\n",
    "    #return h_inverse_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0., 0., 0.,  ..., 0., 0., 0.], grad_fn=<SelectBackward>)\ntorch.Size([351000])\ntensor(0.)\n"
    }
   ],
   "source": [
    "mf = torch.load('model.torch')\n",
    "get_influence(loss_func, train_data[0], test_data, mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}